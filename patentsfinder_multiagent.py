# pip install --upgrade langchain==0.1.14 langgraph==0.0.34 openai google-cloud-bigquery streamlit pandas numpy scikit-learn tiktoken pyyaml

# patentsfinder_multiagent.py

import os
import streamlit as st
import pandas as pd
import numpy as np
from langchain.chat_models import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.pregel import Pregel
from langgraph.graph.message import add_messages
from langgraph.graph.events import EventedGraphRunner
from google.cloud import bigquery
from sklearn.metrics.pairwise import cosine_similarity
from langchain.schema import SystemMessage, HumanMessage
from typing import TypedDict, List, Optional
import json
import re

# --------------------------
# APIã‚­ãƒ¼èªè¨¼ã¨LLMåˆæœŸåŒ–
# --------------------------
openai_api_key = os.getenv("OPENAI_API_KEY")
gcp_json_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

llm = ChatOpenAI(model="gpt-4", temperature=0.2, openai_api_key=openai_api_key)

# --------------------------
# çŠ¶æ…‹å®šç¾©
# --------------------------
class PatentState(TypedDict):
    user_input: str
    tech_views: List[str]
    ipc_candidates: List[str]
    search_params: dict
    patent_df: Optional[pd.DataFrame]
    query_text: Optional[str]
    ranked_df: Optional[pd.DataFrame]
    explanations: Optional[List[str]]
    clarification_needed: Optional[bool]

# --------------------------
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ‰å®šç¾©
# --------------------------

def theme_tech_agent(state: PatentState):
    """æŠ€è¡“è¦³ç‚¹ã‹ã‚‰ã®è¦–ç‚¹æŠ½å‡º"""
    prompt = f"""
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèª¿æŸ»ã—ãŸã„æŠ€è¡“ãƒ†ãƒ¼ãƒã¯: "{state['user_input']}"
    æŠ€è¡“çš„ãªè¦³ç‚¹ã§ã€3ç‚¹ã»ã©é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„é–¢å¿ƒç‚¹ã‚’æŒ™ã’ã¦ãã ã•ã„ã€‚
    """
    resp = llm([HumanMessage(content=prompt)])
    return {"tech_views": [resp.content]}

def theme_market_agent(state: PatentState):
    """å¸‚å ´ç”¨é€”ã‹ã‚‰ã®è¦–ç‚¹æŠ½å‡º"""
    prompt = f"""
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèª¿æŸ»ã—ãŸã„ãƒ†ãƒ¼ãƒã¯: "{state['user_input']}"
    å¸‚å ´ç”¨é€”ã‚„å¿œç”¨å…ˆã®è¦–ç‚¹ã§ã€é–¢é€£ãƒˆãƒ”ãƒƒã‚¯ã‚’3ç‚¹ã»ã©æŒ™ã’ã¦ãã ã•ã„ã€‚
    """
    resp = llm([HumanMessage(content=prompt)])
    return {"tech_views": [resp.content]}

def theme_competitor_agent(state: PatentState):
    """ç«¶åˆæŠ€è¡“è¦–ç‚¹ã®æŠ½å‡º"""
    prompt = f"""
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ†ãƒ¼ãƒ: "{state['user_input']}"
    ç«¶åˆè£½å“ã‚„é–¢é€£ã™ã‚‹ç ”ç©¶ãƒ»æŠ€è¡“ã®è¦³ç‚¹ã‹ã‚‰3ã¤ã»ã©ãƒˆãƒ”ãƒƒã‚¯ã‚’æŒ™ã’ã¦ãã ã•ã„ã€‚
    """
    resp = llm([HumanMessage(content=prompt)])
    return {"tech_views": [resp.content]}

def ipc_classification_agents(state: PatentState):
    """IPCã‚³ãƒ¼ãƒ‰åˆ†é¡ã®ã‚¯ãƒ­ã‚¹ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
    prompt = f"""
    ä»¥ä¸‹ã®æŠ€è¡“è¦³ç‚¹ã«åŸºã¥ã„ã¦ã€é–¢é€£ã™ã‚‹IPCåˆ†é¡ã‚³ãƒ¼ãƒ‰ã‚’3ã€œ5ä»¶ææ¡ˆã—ã¦ãã ã•ã„ã€‚\n{state['tech_views']}
    å‡ºåŠ›å½¢å¼: IPCã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹: A01B33/00ï¼‰ã¨ãã®ç°¡æ½”ãªèª¬æ˜
    """
    resp = llm([HumanMessage(content=prompt)])
    codes = re.findall(r"[A-Z]\d{2}[A-Z]?\s*\d{1,2}/\d{1,2}", resp.content)
    return {"ipc_candidates": list(set(code.replace(" ", "") for code in codes))}

def extract_search_params(state: PatentState):
    """æ¡ä»¶æŠ½å‡º + è£œå®Œï¼ˆå¿…è¦ã‚ã‚Œã°å†è³ªå•ï¼‰"""
    prompt = f"""
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰ä»¥ä¸‹ã®3é …ç›®ã‚’JSONå½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š
    countries, assignees, publication_fromï¼ˆYYYY-MM-DDå½¢å¼ï¼‰ã€‚
    å…¥åŠ›: "{state['user_input']}"
    """
    resp = llm([HumanMessage(content=prompt)])
    try:
        parsed = json.loads(resp.content.strip())
    except json.JSONDecodeError:
        return {"clarification_needed": True}
    return {"search_params": parsed, "clarification_needed": False}

def clarify_params(state: PatentState):
    """æ›–æ˜§æ¡ä»¶ã®è‡ªå‹•ãƒ’ã‚¢ãƒªãƒ³ã‚°"""
    return {
        "search_params": {
            "countries": ["JP"],
            "assignees": [],
            "publication_from": "2020-01-01"
        },
        "clarification_needed": False
    }

def bq_search_agent(state: PatentState):
    """BigQueryæ¤œç´¢"""
    credentials = bigquery.Client.from_service_account_json(gcp_json_path)._credentials
    client = bigquery.Client(credentials=credentials)
    params = state["search_params"]
    ipc_list = [f"'{c}'" for c in state["ipc_candidates"]]
    where = f"ipc.code IN ({','.join(ipc_list)})"
    if "countries" in params:
        where += f" AND country_code IN ({','.join(f'\'{c}\'' for c in params['countries'])})"
    if "assignees" in params and params["assignees"]:
        where += f" AND assignee IN ({','.join(f'\'{a}\'' for a in params['assignees'])})"
    if "publication_from" in params:
        where += f" AND publication_date >= '{params['publication_from']}'"
    sql = f"""
    SELECT
        publication_number,
        (SELECT v.text FROM UNNEST(title_localized) AS v WHERE v.language='en' LIMIT 1) AS title,
        (SELECT v.text FROM UNNEST(abstract_localized) AS v WHERE v.language='en' LIMIT 1) AS abstract,
        publication_date
    FROM `patents-public-data.patents.publications` AS p
        LEFT JOIN UNNEST(p.ipc) AS ipc
    WHERE {where}
    LIMIT 50
    """
    df = client.query(sql).to_dataframe()
    return {"patent_df": df}

def similarity_rank_agent(state: PatentState):
    """Embeddingã«ã‚ˆã‚‹é¡ä¼¼åº¦è©•ä¾¡"""
    import openai
    openai.api_key = openai_api_key
    abstracts = state["patent_df"]["abstract"].fillna("").tolist()
    query = state["user_input"]
    query_vec = openai.Embedding.create(input=query, model="text-embedding-ada-002")["data"][0]["embedding"]
    patent_vecs = [openai.Embedding.create(input=abs, model="text-embedding-ada-002")["data"][0]["embedding"] for abs in abstracts]
    sims = cosine_similarity([query_vec], patent_vecs)[0]
    df = state["patent_df"].copy()
    df["similarity"] = sims
    df_sorted = df.sort_values("similarity", ascending=False)
    return {"ranked_df": df_sorted}

def explanation_agent(state: PatentState):
    """æ—¥æœ¬èªã«ã‚ˆã‚‹ã‚„ã•ã—ã„ç‰¹è¨±è¦ç´„"""
    top3 = state["ranked_df"].head(3)
    explanations = []
    for _, row in top3.iterrows():
        prompt = f"ä»¥ä¸‹ã®ç‰¹è¨±è¦ç´„ã‚’200å­—ä»¥å†…ã®ç°¡å˜ãªæ—¥æœ¬èªã§è§£èª¬ã—ã¦ãã ã•ã„ï¼š\n{row['abstract']}"
        resp = llm([HumanMessage(content=prompt)])
        explanations.append(resp.content.strip())
    return {"explanations": explanations}

def orchestrator_agent(state: PatentState):
    """æœ€çµ‚å‡ºåŠ›ï¼šçµ±åˆã¨è¡¨ç¤ºæŒ‡ç¤º"""
    st.markdown("## ğŸ“˜ AIç‰¹è¨±èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ")
    st.markdown("### ğŸ” é¡ä¼¼ç‰¹è¨±ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    st.dataframe(state["ranked_df"][["title", "similarity", "publication_date"]])
    st.markdown("### ğŸ“ æ—¥æœ¬èªè¦ç´„")
    for i, exp in enumerate(state["explanations"], 1):
        st.markdown(f"**{i}.** {exp}")
    return {}

# --------------------------
# LangGraph ã‚°ãƒ©ãƒ•æ§‹æˆ
# --------------------------
builder = StateGraph(PatentState)

# ãƒ†ãƒ¼ãƒç†è§£ï¼šä¸¦åˆ—è¦–ç‚¹ï¼ˆæŠ€è¡“ãƒ»å¸‚å ´ãƒ»ç«¶åˆï¼‰
builder.add_node("theme_tech", theme_tech_agent)
builder.add_node("theme_market", theme_market_agent)
builder.add_node("theme_competitor", theme_competitor_agent)
builder.add_node("ipc_classify", ipc_classification_agents)
builder.add_node("extract_params", extract_search_params)
builder.add_node("clarify", clarify_params)
builder.add_node("bq_search", bq_search_agent)
builder.add_node("similarity", similarity_rank_agent)
builder.add_node("explain", explanation_agent)
builder.add_node("orchestrator", orchestrator_agent)

builder.set_entry_point("theme_tech")
builder.add_edge("theme_tech", "theme_market")
builder.add_edge("theme_market", "theme_competitor")
builder.add_edge("theme_competitor", "ipc_classify")
builder.add_edge("ipc_classify", "extract_params")

# æ¡ä»¶ã®æ›–æ˜§ã•ã«ã‚ˆã‚‹åˆ†å²
builder.add_conditional_edges(
    "extract_params",
    lambda state: "clarify" if state.get("clarification_needed") else "bq_search",
    {"clarify": "clarify", "bq_search": "bq_search"}
)
builder.add_edge("clarify", "bq_search")
builder.add_edge("bq_search", "similarity")
builder.add_edge("similarity", "explain")
builder.add_edge("explain", "orchestrator")
builder.add_edge("orchestrator", END)

graph = builder.compile()

# --------------------------
# Streamlit UI
# --------------------------
st.set_page_config(page_title="ğŸ” PatentsFinder Multi-Agent", layout="wide")
st.title("ğŸ” PatentsFinder Multi-Agent by LangGraph")

user_input = st.text_input("èª¿æŸ»ã—ãŸã„æŠ€è¡“å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹ï¼šé€†æµ¸é€è†œã®ãƒ•ã‚¡ã‚¦ãƒªãƒ³ã‚°æŠ‘åˆ¶æŠ€è¡“")

if st.button("èª¿æŸ»é–‹å§‹") and user_input:
    initial_state = PatentState(user_input=user_input, tech_views=[], ipc_candidates=[], search_params={})
    graph.invoke(initial_state)
